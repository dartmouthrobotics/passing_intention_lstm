{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "756d8e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mingi/anaconda3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# essential packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# python modules\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# custom module\n",
    "from aux_code.learning_preprocess import convert_from_NED_to_Robotic, get_trajectory_before_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e7f99193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from ray import tune\n",
    "from ray.air import Checkpoint, session\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dab6f09",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bb0cf124",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"aisdk_20180101\"\n",
    "howmany=200\n",
    "using_file_indices = np.arange(0,howmany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c7b4d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entire_pass = pd.DataFrame()\n",
    "\n",
    "# https://www.w3resource.com/pandas/dataframe/dataframe-to_pickle.php\n",
    "for using_file_idx in using_file_indices:\n",
    "    unpickled_df = pd.read_pickle(\"./dk_csv_20180101/aisdk_20180101_{}.pkl\".format(str(using_file_idx)))\n",
    "    unpickled_df\n",
    "    df_entire_pass = pd.concat([df_entire_pass, unpickled_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "37ad7a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>v_x</th>\n",
       "      <th>v_y</th>\n",
       "      <th>rel_dist</th>\n",
       "      <th>rel_bearing</th>\n",
       "      <th>rel_bearing_diff</th>\n",
       "      <th>Heading</th>\n",
       "      <th>valid</th>\n",
       "      <th>obj_index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:34:30</th>\n",
       "      <td>4.214136</td>\n",
       "      <td>2.391927</td>\n",
       "      <td>-0.009386</td>\n",
       "      <td>-0.006086</td>\n",
       "      <td>4.845643</td>\n",
       "      <td>0.516252</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>145.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:34:45</th>\n",
       "      <td>4.086469</td>\n",
       "      <td>2.312937</td>\n",
       "      <td>-0.008511</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>4.695626</td>\n",
       "      <td>0.515043</td>\n",
       "      <td>-0.001209</td>\n",
       "      <td>145.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:35:00</th>\n",
       "      <td>3.972708</td>\n",
       "      <td>2.235017</td>\n",
       "      <td>-0.007584</td>\n",
       "      <td>-0.005195</td>\n",
       "      <td>4.558257</td>\n",
       "      <td>0.512460</td>\n",
       "      <td>-0.002584</td>\n",
       "      <td>147.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:35:15</th>\n",
       "      <td>3.857949</td>\n",
       "      <td>2.154808</td>\n",
       "      <td>-0.007651</td>\n",
       "      <td>-0.005347</td>\n",
       "      <td>4.418933</td>\n",
       "      <td>0.509374</td>\n",
       "      <td>-0.003086</td>\n",
       "      <td>150.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:35:30</th>\n",
       "      <td>3.730337</td>\n",
       "      <td>2.078144</td>\n",
       "      <td>-0.008507</td>\n",
       "      <td>-0.005111</td>\n",
       "      <td>4.270140</td>\n",
       "      <td>0.508272</td>\n",
       "      <td>-0.001102</td>\n",
       "      <td>150.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 11:37:00</th>\n",
       "      <td>-0.388895</td>\n",
       "      <td>0.516592</td>\n",
       "      <td>-0.002982</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.646611</td>\n",
       "      <td>2.216093</td>\n",
       "      <td>0.012567</td>\n",
       "      <td>235.0</td>\n",
       "      <td>True</td>\n",
       "      <td>199</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 11:37:15</th>\n",
       "      <td>-0.433163</td>\n",
       "      <td>0.564382</td>\n",
       "      <td>-0.002951</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.711447</td>\n",
       "      <td>2.225403</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>235.0</td>\n",
       "      <td>True</td>\n",
       "      <td>199</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 11:37:30</th>\n",
       "      <td>-0.475801</td>\n",
       "      <td>0.610369</td>\n",
       "      <td>-0.002843</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>0.773910</td>\n",
       "      <td>2.232930</td>\n",
       "      <td>0.007527</td>\n",
       "      <td>234.0</td>\n",
       "      <td>True</td>\n",
       "      <td>199</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 11:37:45</th>\n",
       "      <td>-0.520051</td>\n",
       "      <td>0.660504</td>\n",
       "      <td>-0.002950</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>0.840666</td>\n",
       "      <td>2.237780</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>199</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 11:38:00</th>\n",
       "      <td>-0.580154</td>\n",
       "      <td>0.725169</td>\n",
       "      <td>-0.004007</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.928681</td>\n",
       "      <td>2.245553</td>\n",
       "      <td>0.007774</td>\n",
       "      <td>231.0</td>\n",
       "      <td>True</td>\n",
       "      <td>199</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52343 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            x         y       v_x       v_y  rel_dist  \\\n",
       "Timestamp                                                               \n",
       "2018-01-01 23:34:30  4.214136  2.391927 -0.009386 -0.006086  4.845643   \n",
       "2018-01-01 23:34:45  4.086469  2.312937 -0.008511 -0.005266  4.695626   \n",
       "2018-01-01 23:35:00  3.972708  2.235017 -0.007584 -0.005195  4.558257   \n",
       "2018-01-01 23:35:15  3.857949  2.154808 -0.007651 -0.005347  4.418933   \n",
       "2018-01-01 23:35:30  3.730337  2.078144 -0.008507 -0.005111  4.270140   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2018-01-01 11:37:00 -0.388895  0.516592 -0.002982  0.003150  0.646611   \n",
       "2018-01-01 11:37:15 -0.433163  0.564382 -0.002951  0.003186  0.711447   \n",
       "2018-01-01 11:37:30 -0.475801  0.610369 -0.002843  0.003066  0.773910   \n",
       "2018-01-01 11:37:45 -0.520051  0.660504 -0.002950  0.003342  0.840666   \n",
       "2018-01-01 11:38:00 -0.580154  0.725169 -0.004007  0.004311  0.928681   \n",
       "\n",
       "                     rel_bearing  rel_bearing_diff  Heading  valid  obj_index  \\\n",
       "Timestamp                                                                       \n",
       "2018-01-01 23:34:30     0.516252         -0.001975    145.0   True          0   \n",
       "2018-01-01 23:34:45     0.515043         -0.001209    145.5   True          0   \n",
       "2018-01-01 23:35:00     0.512460         -0.002584    147.0   True          0   \n",
       "2018-01-01 23:35:15     0.509374         -0.003086    150.5   True          0   \n",
       "2018-01-01 23:35:30     0.508272         -0.001102    150.0   True          0   \n",
       "...                          ...               ...      ...    ...        ...   \n",
       "2018-01-01 11:37:00     2.216093          0.012567    235.0   True        199   \n",
       "2018-01-01 11:37:15     2.225403          0.009310    235.0   True        199   \n",
       "2018-01-01 11:37:30     2.232930          0.007527    234.0   True        199   \n",
       "2018-01-01 11:37:45     2.237780          0.004850    233.0   True        199   \n",
       "2018-01-01 11:38:00     2.245553          0.007774    231.0   True        199   \n",
       "\n",
       "                    label  \n",
       "Timestamp                  \n",
       "2018-01-01 23:34:30     L  \n",
       "2018-01-01 23:34:45     L  \n",
       "2018-01-01 23:35:00     L  \n",
       "2018-01-01 23:35:15     L  \n",
       "2018-01-01 23:35:30     L  \n",
       "...                   ...  \n",
       "2018-01-01 11:37:00     L  \n",
       "2018-01-01 11:37:15     L  \n",
       "2018-01-01 11:37:30     L  \n",
       "2018-01-01 11:37:45     L  \n",
       "2018-01-01 11:38:00     L  \n",
       "\n",
       "[52343 rows x 11 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entire_pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dde3dd4",
   "metadata": {},
   "source": [
    "### pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "04e6d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entire_pass['heading_converted']  = np.deg2rad(df_entire_pass['Heading'])\n",
    "# lambda function method: very fast! \n",
    "# https://stackoverflow.com/questions/71249186/applying-function-to-column-in-a-dataframe\n",
    "df_entire_pass['heading_converted'] = df_entire_pass['heading_converted'].apply(convert_from_NED_to_Robotic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b8034fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>v_x</th>\n",
       "      <th>v_y</th>\n",
       "      <th>rel_dist</th>\n",
       "      <th>rel_bearing</th>\n",
       "      <th>rel_bearing_diff</th>\n",
       "      <th>Heading</th>\n",
       "      <th>valid</th>\n",
       "      <th>obj_index</th>\n",
       "      <th>label</th>\n",
       "      <th>heading_converted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:34:30</th>\n",
       "      <td>4.214136</td>\n",
       "      <td>2.391927</td>\n",
       "      <td>-0.009386</td>\n",
       "      <td>-0.006086</td>\n",
       "      <td>4.845643</td>\n",
       "      <td>0.516252</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>145.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>-0.959931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:34:45</th>\n",
       "      <td>4.086469</td>\n",
       "      <td>2.312937</td>\n",
       "      <td>-0.008511</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>4.695626</td>\n",
       "      <td>0.515043</td>\n",
       "      <td>-0.001209</td>\n",
       "      <td>145.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>-0.968658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:35:00</th>\n",
       "      <td>3.972708</td>\n",
       "      <td>2.235017</td>\n",
       "      <td>-0.007584</td>\n",
       "      <td>-0.005195</td>\n",
       "      <td>4.558257</td>\n",
       "      <td>0.512460</td>\n",
       "      <td>-0.002584</td>\n",
       "      <td>147.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>-0.994838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:35:15</th>\n",
       "      <td>3.857949</td>\n",
       "      <td>2.154808</td>\n",
       "      <td>-0.007651</td>\n",
       "      <td>-0.005347</td>\n",
       "      <td>4.418933</td>\n",
       "      <td>0.509374</td>\n",
       "      <td>-0.003086</td>\n",
       "      <td>150.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>-1.055924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:35:30</th>\n",
       "      <td>3.730337</td>\n",
       "      <td>2.078144</td>\n",
       "      <td>-0.008507</td>\n",
       "      <td>-0.005111</td>\n",
       "      <td>4.270140</td>\n",
       "      <td>0.508272</td>\n",
       "      <td>-0.001102</td>\n",
       "      <td>150.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>-1.047198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 11:37:00</th>\n",
       "      <td>-0.388895</td>\n",
       "      <td>0.516592</td>\n",
       "      <td>-0.002982</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.646611</td>\n",
       "      <td>2.216093</td>\n",
       "      <td>0.012567</td>\n",
       "      <td>235.0</td>\n",
       "      <td>True</td>\n",
       "      <td>199</td>\n",
       "      <td>L</td>\n",
       "      <td>-2.530727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 11:37:15</th>\n",
       "      <td>-0.433163</td>\n",
       "      <td>0.564382</td>\n",
       "      <td>-0.002951</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.711447</td>\n",
       "      <td>2.225403</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>235.0</td>\n",
       "      <td>True</td>\n",
       "      <td>199</td>\n",
       "      <td>L</td>\n",
       "      <td>-2.530727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 11:37:30</th>\n",
       "      <td>-0.475801</td>\n",
       "      <td>0.610369</td>\n",
       "      <td>-0.002843</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>0.773910</td>\n",
       "      <td>2.232930</td>\n",
       "      <td>0.007527</td>\n",
       "      <td>234.0</td>\n",
       "      <td>True</td>\n",
       "      <td>199</td>\n",
       "      <td>L</td>\n",
       "      <td>-2.513274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 11:37:45</th>\n",
       "      <td>-0.520051</td>\n",
       "      <td>0.660504</td>\n",
       "      <td>-0.002950</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>0.840666</td>\n",
       "      <td>2.237780</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>199</td>\n",
       "      <td>L</td>\n",
       "      <td>-2.495821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 11:38:00</th>\n",
       "      <td>-0.580154</td>\n",
       "      <td>0.725169</td>\n",
       "      <td>-0.004007</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.928681</td>\n",
       "      <td>2.245553</td>\n",
       "      <td>0.007774</td>\n",
       "      <td>231.0</td>\n",
       "      <td>True</td>\n",
       "      <td>199</td>\n",
       "      <td>L</td>\n",
       "      <td>-2.460914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52343 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            x         y       v_x       v_y  rel_dist  \\\n",
       "Timestamp                                                               \n",
       "2018-01-01 23:34:30  4.214136  2.391927 -0.009386 -0.006086  4.845643   \n",
       "2018-01-01 23:34:45  4.086469  2.312937 -0.008511 -0.005266  4.695626   \n",
       "2018-01-01 23:35:00  3.972708  2.235017 -0.007584 -0.005195  4.558257   \n",
       "2018-01-01 23:35:15  3.857949  2.154808 -0.007651 -0.005347  4.418933   \n",
       "2018-01-01 23:35:30  3.730337  2.078144 -0.008507 -0.005111  4.270140   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2018-01-01 11:37:00 -0.388895  0.516592 -0.002982  0.003150  0.646611   \n",
       "2018-01-01 11:37:15 -0.433163  0.564382 -0.002951  0.003186  0.711447   \n",
       "2018-01-01 11:37:30 -0.475801  0.610369 -0.002843  0.003066  0.773910   \n",
       "2018-01-01 11:37:45 -0.520051  0.660504 -0.002950  0.003342  0.840666   \n",
       "2018-01-01 11:38:00 -0.580154  0.725169 -0.004007  0.004311  0.928681   \n",
       "\n",
       "                     rel_bearing  rel_bearing_diff  Heading  valid  obj_index  \\\n",
       "Timestamp                                                                       \n",
       "2018-01-01 23:34:30     0.516252         -0.001975    145.0   True          0   \n",
       "2018-01-01 23:34:45     0.515043         -0.001209    145.5   True          0   \n",
       "2018-01-01 23:35:00     0.512460         -0.002584    147.0   True          0   \n",
       "2018-01-01 23:35:15     0.509374         -0.003086    150.5   True          0   \n",
       "2018-01-01 23:35:30     0.508272         -0.001102    150.0   True          0   \n",
       "...                          ...               ...      ...    ...        ...   \n",
       "2018-01-01 11:37:00     2.216093          0.012567    235.0   True        199   \n",
       "2018-01-01 11:37:15     2.225403          0.009310    235.0   True        199   \n",
       "2018-01-01 11:37:30     2.232930          0.007527    234.0   True        199   \n",
       "2018-01-01 11:37:45     2.237780          0.004850    233.0   True        199   \n",
       "2018-01-01 11:38:00     2.245553          0.007774    231.0   True        199   \n",
       "\n",
       "                    label  heading_converted  \n",
       "Timestamp                                     \n",
       "2018-01-01 23:34:30     L          -0.959931  \n",
       "2018-01-01 23:34:45     L          -0.968658  \n",
       "2018-01-01 23:35:00     L          -0.994838  \n",
       "2018-01-01 23:35:15     L          -1.055924  \n",
       "2018-01-01 23:35:30     L          -1.047198  \n",
       "...                   ...                ...  \n",
       "2018-01-01 11:37:00     L          -2.530727  \n",
       "2018-01-01 11:37:15     L          -2.530727  \n",
       "2018-01-01 11:37:30     L          -2.513274  \n",
       "2018-01-01 11:37:45     L          -2.495821  \n",
       "2018-01-01 11:38:00     L          -2.460914  \n",
       "\n",
       "[52343 rows x 12 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entire_pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d392c52",
   "metadata": {},
   "source": [
    "## Train, test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "526595ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 160 \n",
      " test size: 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([176,  86, 171, 194, 186, 179,  28, 172,  94, 146,  13, 178,  15,\n",
       "       148,  12, 145, 182,  46,  45,  56,  66, 191,  23, 142, 134,   4,\n",
       "       141, 163,  67, 152,  54, 107, 112, 116, 190, 168,  19,  70, 161,\n",
       "       147,  68,  79,  30,  53, 193, 136,  44, 149, 101,  97,  21,  63,\n",
       "         7,  75,  20,  64, 187,  85,  36, 164, 111,  55,   1,  48,  78,\n",
       "        96,  76, 170, 104, 137, 115, 129, 127, 124,  22,  18, 199, 167,\n",
       "        51,  73, 162,  71, 183,  60, 130,  37,  69,  72,   9,  88,  17,\n",
       "        59, 126, 110, 128, 144,  11,  26, 156, 108, 177,   3,  77, 139,\n",
       "        31, 109, 133, 122,  10, 113, 165, 123, 151,  25,  41,  34,  27,\n",
       "        80, 118,  58,  40,  90, 160,  32, 103, 197, 184, 192, 157,  84,\n",
       "       166,  81, 188,  14,  93, 153,  24, 195,  92, 169, 132,  47,  95,\n",
       "       120,  29, 125, 198,  57, 173, 185, 121,  98,  33, 181,  83,  74,\n",
       "       131, 196, 117,  39])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.geeksforgeeks.org/how-to-randomly-select-elements-of-an-array-with-numpy-in-python/\n",
    "\n",
    "# np.random.seed(0) # right now for consistent data testing\n",
    "\n",
    "\n",
    "# for train, test data\n",
    "use_df = df_entire_pass.loc[(df_entire_pass.valid == True)] # to be used, valid df\n",
    "unique_id = use_df.obj_index.unique()\n",
    "\n",
    "# data split\n",
    "train_data_size = int(len(unique_id) * 0.8)\n",
    "test_data_size = len(unique_id) - train_data_size\n",
    "print(\"train size: {} \\n test size: {}\".format(train_data_size, test_data_size))\n",
    "\n",
    "# split obj indexes\n",
    "train_obj_id = np.random.choice(unique_id, size = train_data_size, replace=False)\n",
    "test_obj_id = np.setdiff1d(unique_id, train_obj_id)\n",
    "train_obj_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "adddad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dimension(x_data, y_data):\n",
    "    if len(x_data) == len(y_data):\n",
    "        print(\"Input, output dimension is same. good to go\")\n",
    "    else:\n",
    "        raise ValueError(\"Input, output dimension is different. Double check!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "27158cab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>v_x</th>\n",
       "      <th>v_y</th>\n",
       "      <th>rel_dist</th>\n",
       "      <th>rel_bearing</th>\n",
       "      <th>rel_bearing_diff</th>\n",
       "      <th>Heading</th>\n",
       "      <th>valid</th>\n",
       "      <th>obj_index</th>\n",
       "      <th>label</th>\n",
       "      <th>heading_converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.506382</td>\n",
       "      <td>-2.131028</td>\n",
       "      <td>-0.001686</td>\n",
       "      <td>0.004118</td>\n",
       "      <td>4.984853</td>\n",
       "      <td>-0.441726</td>\n",
       "      <td>0.008945</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>176</td>\n",
       "      <td>L</td>\n",
       "      <td>-2.809980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.481085</td>\n",
       "      <td>-2.069254</td>\n",
       "      <td>-0.001686</td>\n",
       "      <td>0.004118</td>\n",
       "      <td>4.935781</td>\n",
       "      <td>-0.432603</td>\n",
       "      <td>0.009123</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>176</td>\n",
       "      <td>L</td>\n",
       "      <td>-2.792527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.451802</td>\n",
       "      <td>-2.005076</td>\n",
       "      <td>-0.001952</td>\n",
       "      <td>0.004279</td>\n",
       "      <td>4.882506</td>\n",
       "      <td>-0.423184</td>\n",
       "      <td>0.009419</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>176</td>\n",
       "      <td>L</td>\n",
       "      <td>-2.775074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.434531</td>\n",
       "      <td>-1.968834</td>\n",
       "      <td>-0.001151</td>\n",
       "      <td>0.002416</td>\n",
       "      <td>4.851945</td>\n",
       "      <td>-0.417835</td>\n",
       "      <td>0.005349</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>176</td>\n",
       "      <td>L</td>\n",
       "      <td>-2.757620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.395439</td>\n",
       "      <td>-1.888308</td>\n",
       "      <td>-0.002606</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>4.783889</td>\n",
       "      <td>-0.405766</td>\n",
       "      <td>0.012069</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>176</td>\n",
       "      <td>L</td>\n",
       "      <td>-2.687807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35625</th>\n",
       "      <td>0.404765</td>\n",
       "      <td>-0.095161</td>\n",
       "      <td>-0.006227</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.415800</td>\n",
       "      <td>-0.230908</td>\n",
       "      <td>-0.040407</td>\n",
       "      <td>203.974359</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "      <td>L</td>\n",
       "      <td>-1.989228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35626</th>\n",
       "      <td>0.311353</td>\n",
       "      <td>-0.094254</td>\n",
       "      <td>-0.006227</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.325307</td>\n",
       "      <td>-0.293952</td>\n",
       "      <td>-0.063044</td>\n",
       "      <td>204.025641</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "      <td>L</td>\n",
       "      <td>-1.990123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35627</th>\n",
       "      <td>0.166101</td>\n",
       "      <td>-0.070444</td>\n",
       "      <td>-0.009683</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.180422</td>\n",
       "      <td>-0.401112</td>\n",
       "      <td>-0.107159</td>\n",
       "      <td>204.076923</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "      <td>L</td>\n",
       "      <td>-1.991018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35628</th>\n",
       "      <td>0.086079</td>\n",
       "      <td>-0.050884</td>\n",
       "      <td>-0.005335</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.099994</td>\n",
       "      <td>-0.533874</td>\n",
       "      <td>-0.132763</td>\n",
       "      <td>204.128205</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "      <td>L</td>\n",
       "      <td>-1.991913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35629</th>\n",
       "      <td>0.006057</td>\n",
       "      <td>-0.031324</td>\n",
       "      <td>-0.005335</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.031905</td>\n",
       "      <td>-1.379777</td>\n",
       "      <td>-0.845902</td>\n",
       "      <td>204.179487</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "      <td>L</td>\n",
       "      <td>-1.992808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35630 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x         y       v_x       v_y  rel_dist  rel_bearing  \\\n",
       "0      4.506382 -2.131028 -0.001686  0.004118  4.984853    -0.441726   \n",
       "1      4.481085 -2.069254 -0.001686  0.004118  4.935781    -0.432603   \n",
       "2      4.451802 -2.005076 -0.001952  0.004279  4.882506    -0.423184   \n",
       "3      4.434531 -1.968834 -0.001151  0.002416  4.851945    -0.417835   \n",
       "4      4.395439 -1.888308 -0.002606  0.005368  4.783889    -0.405766   \n",
       "...         ...       ...       ...       ...       ...          ...   \n",
       "35625  0.404765 -0.095161 -0.006227  0.000060  0.415800    -0.230908   \n",
       "35626  0.311353 -0.094254 -0.006227  0.000060  0.325307    -0.293952   \n",
       "35627  0.166101 -0.070444 -0.009683  0.001587  0.180422    -0.401112   \n",
       "35628  0.086079 -0.050884 -0.005335  0.001304  0.099994    -0.533874   \n",
       "35629  0.006057 -0.031324 -0.005335  0.001304  0.031905    -1.379777   \n",
       "\n",
       "       rel_bearing_diff     Heading  valid  obj_index label  heading_converted  \n",
       "0              0.008945  251.000000   True        176     L          -2.809980  \n",
       "1              0.009123  250.000000   True        176     L          -2.792527  \n",
       "2              0.009419  249.000000   True        176     L          -2.775074  \n",
       "3              0.005349  248.000000   True        176     L          -2.757620  \n",
       "4              0.012069  244.000000   True        176     L          -2.687807  \n",
       "...                 ...         ...    ...        ...   ...                ...  \n",
       "35625         -0.040407  203.974359   True         39     L          -1.989228  \n",
       "35626         -0.063044  204.025641   True         39     L          -1.990123  \n",
       "35627         -0.107159  204.076923   True         39     L          -1.991018  \n",
       "35628         -0.132763  204.128205   True         39     L          -1.991913  \n",
       "35629         -0.845902  204.179487   True         39     L          -1.992808  \n",
       "\n",
       "[35630 rows x 12 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "df_cropped_train = get_trajectory_before_pass(df_entire_pass, train_obj_id)\n",
    "df_cropped_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "28e857f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(df_cropped_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f11c1f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(df_cropped_train['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "336d5754",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>v_x</th>\n",
       "      <th>v_y</th>\n",
       "      <th>rel_dist</th>\n",
       "      <th>rel_bearing</th>\n",
       "      <th>rel_bearing_diff</th>\n",
       "      <th>Heading</th>\n",
       "      <th>valid</th>\n",
       "      <th>obj_index</th>\n",
       "      <th>label</th>\n",
       "      <th>heading_converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.214136</td>\n",
       "      <td>2.391927</td>\n",
       "      <td>-0.009386</td>\n",
       "      <td>-0.006086</td>\n",
       "      <td>4.845643</td>\n",
       "      <td>0.516252</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>145.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>-0.959931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.086469</td>\n",
       "      <td>2.312937</td>\n",
       "      <td>-0.008511</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>4.695626</td>\n",
       "      <td>0.515043</td>\n",
       "      <td>-0.001209</td>\n",
       "      <td>145.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>-0.968658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.972708</td>\n",
       "      <td>2.235017</td>\n",
       "      <td>-0.007584</td>\n",
       "      <td>-0.005195</td>\n",
       "      <td>4.558257</td>\n",
       "      <td>0.512460</td>\n",
       "      <td>-0.002584</td>\n",
       "      <td>147.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>-0.994838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.857949</td>\n",
       "      <td>2.154808</td>\n",
       "      <td>-0.007651</td>\n",
       "      <td>-0.005347</td>\n",
       "      <td>4.418933</td>\n",
       "      <td>0.509374</td>\n",
       "      <td>-0.003086</td>\n",
       "      <td>150.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>-1.055924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.730337</td>\n",
       "      <td>2.078144</td>\n",
       "      <td>-0.008507</td>\n",
       "      <td>-0.005111</td>\n",
       "      <td>4.270140</td>\n",
       "      <td>0.508272</td>\n",
       "      <td>-0.001102</td>\n",
       "      <td>150.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>-1.047198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9312</th>\n",
       "      <td>0.290117</td>\n",
       "      <td>0.043699</td>\n",
       "      <td>-0.002775</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.293389</td>\n",
       "      <td>0.149501</td>\n",
       "      <td>0.079311</td>\n",
       "      <td>198.0</td>\n",
       "      <td>True</td>\n",
       "      <td>189</td>\n",
       "      <td>L</td>\n",
       "      <td>-1.884956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9313</th>\n",
       "      <td>0.250299</td>\n",
       "      <td>0.053381</td>\n",
       "      <td>-0.002654</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.255928</td>\n",
       "      <td>0.210120</td>\n",
       "      <td>0.060619</td>\n",
       "      <td>198.0</td>\n",
       "      <td>True</td>\n",
       "      <td>189</td>\n",
       "      <td>L</td>\n",
       "      <td>-1.884956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9314</th>\n",
       "      <td>0.179070</td>\n",
       "      <td>0.068803</td>\n",
       "      <td>-0.004749</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.191833</td>\n",
       "      <td>0.366834</td>\n",
       "      <td>0.156714</td>\n",
       "      <td>198.0</td>\n",
       "      <td>True</td>\n",
       "      <td>189</td>\n",
       "      <td>L</td>\n",
       "      <td>-1.884956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9315</th>\n",
       "      <td>0.122623</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>-0.003763</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.150158</td>\n",
       "      <td>0.615258</td>\n",
       "      <td>0.248425</td>\n",
       "      <td>197.0</td>\n",
       "      <td>True</td>\n",
       "      <td>189</td>\n",
       "      <td>L</td>\n",
       "      <td>-1.867502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9316</th>\n",
       "      <td>0.060548</td>\n",
       "      <td>0.092641</td>\n",
       "      <td>-0.004138</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.110673</td>\n",
       "      <td>0.991910</td>\n",
       "      <td>0.376651</td>\n",
       "      <td>196.5</td>\n",
       "      <td>True</td>\n",
       "      <td>189</td>\n",
       "      <td>L</td>\n",
       "      <td>-1.858776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9317 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x         y       v_x       v_y  rel_dist  rel_bearing  \\\n",
       "0     4.214136  2.391927 -0.009386 -0.006086  4.845643     0.516252   \n",
       "1     4.086469  2.312937 -0.008511 -0.005266  4.695626     0.515043   \n",
       "2     3.972708  2.235017 -0.007584 -0.005195  4.558257     0.512460   \n",
       "3     3.857949  2.154808 -0.007651 -0.005347  4.418933     0.509374   \n",
       "4     3.730337  2.078144 -0.008507 -0.005111  4.270140     0.508272   \n",
       "...        ...       ...       ...       ...       ...          ...   \n",
       "9312  0.290117  0.043699 -0.002775  0.001358  0.293389     0.149501   \n",
       "9313  0.250299  0.053381 -0.002654  0.000645  0.255928     0.210120   \n",
       "9314  0.179070  0.068803 -0.004749  0.001028  0.191833     0.366834   \n",
       "9315  0.122623  0.086667 -0.003763  0.001191  0.150158     0.615258   \n",
       "9316  0.060548  0.092641 -0.004138  0.000398  0.110673     0.991910   \n",
       "\n",
       "      rel_bearing_diff  Heading  valid  obj_index label  heading_converted  \n",
       "0            -0.001975    145.0   True          0     L          -0.959931  \n",
       "1            -0.001209    145.5   True          0     L          -0.968658  \n",
       "2            -0.002584    147.0   True          0     L          -0.994838  \n",
       "3            -0.003086    150.5   True          0     L          -1.055924  \n",
       "4            -0.001102    150.0   True          0     L          -1.047198  \n",
       "...                ...      ...    ...        ...   ...                ...  \n",
       "9312          0.079311    198.0   True        189     L          -1.884956  \n",
       "9313          0.060619    198.0   True        189     L          -1.884956  \n",
       "9314          0.156714    198.0   True        189     L          -1.884956  \n",
       "9315          0.248425    197.0   True        189     L          -1.867502  \n",
       "9316          0.376651    196.5   True        189     L          -1.858776  \n",
       "\n",
       "[9317 rows x 12 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data\n",
    "df_cropped_test = get_trajectory_before_pass(df_entire_pass, test_obj_id)\n",
    "df_cropped_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9785d11",
   "metadata": {},
   "source": [
    "## Train, test data onehot encoding and extract specific cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ff3e75e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input, output dimension is same. good to go\n",
      "Input, output dimension is same. good to go\n"
     ]
    }
   ],
   "source": [
    "# columns to extract\n",
    "columns_for_x = ['x', 'y', 'rel_dist', 'rel_bearing', 'heading_converted']\n",
    "# columns_for_x = ['r_value', 'atan']\n",
    "columns_for_y = ['label']\n",
    "\n",
    "# one hot encoding for y target\n",
    "one_hot_lookup = torch.eye(2).tolist()\n",
    "\n",
    "# df to array\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "#### train dataset\n",
    "for obj_id, df_by_ID in df_cropped_train.groupby('obj_index'):\n",
    "    X_train.append(df_by_ID[columns_for_x].values.tolist())\n",
    "    # y_train.append(one_hot_lookup[0] if df_by_ID[columns_for_y].values[-1][0] == \"L\" else one_hot_lookup[1]) # last row, only char\n",
    "    y_train.append(0 if df_by_ID[columns_for_y].values[-1][0] == \"L\" else 1) # last row, only char\n",
    "\n",
    "    #### double check train dataset\n",
    "check_dimension(X_train, y_train)\n",
    "\n",
    "#### test dataset\n",
    "for obj_id, df_by_ID in df_cropped_test.groupby('obj_index'):\n",
    "    X_test.append(df_by_ID[columns_for_x].values.tolist())\n",
    "    # y_test.append(one_hot_lookup[0] if df_by_ID[columns_for_y].values[-1][0] == \"L\" else one_hot_lookup[1]) # last row, only char\n",
    "    y_test.append(0 if df_by_ID[columns_for_y].values[-1][0] == \"L\" else 1) # last row, only char\n",
    "\n",
    "#### double check test dataset\n",
    "check_dimension(X_test, y_test)\n",
    "\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb68535",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e032b8cd",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a48dec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {\n",
    "#     \"hidden_size\": tune.choice([2 ** i for i in range(7,9)]),\n",
    "#     \"num_layers\": tune.choice([2* (i+1) for i in range(3,5)]),\n",
    "#     \"lr\": tune.loguniform(1e-2, 1e-1),\n",
    "#     \"batch_size\": tune.choice([16, 32]),\n",
    "#     \"step_size\": tune.choice([50, 100]), \n",
    "#     \"gamma\": tune.choice([0.1* (i+1) for i in range(7, 9)])\n",
    "    \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b6763c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"hidden_size\": tune.choice([2 ** (i+1) for i in range(4,9)]),\n",
    "    \"num_layers\": tune.choice([2* (i+1) for i in range(2,5)]),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"batch_size\": tune.choice([2, 4, 8, 16, 32]),\n",
    "    \"step_size\": tune.choice([20, 30, 40, 50, 100, 150])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "27c54e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {\n",
    "#     \"hidden_size\": tune.grid_search([2 ** (i+1) for i in range(9)]),\n",
    "#     \"num_layers\": tune.grid_search([2* (i+1) for i in range(5)]),\n",
    "#     \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "#     \"batch_size\": tune.grid_search([2, 4, 8, 16, 32]),\n",
    "#     \"step_size\": tune.grid_search([20, 40, 100]), \n",
    "#     \"gamma\": tune.grid_search([0.1* (i+1) for i in range(5)])\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b59c5a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequence_length = 10 # number of timestamps # padding\n",
    "input_size = 5 # number of columns, features\n",
    "batch_size = config['batch_size'] # number of samples sent to the model at one time 32\n",
    "\n",
    "hidden_size = config['hidden_size'] # dimension of hidden state # 500\n",
    "num_layers = config['num_layers']  # total layer\n",
    "num_classes = 1 # output class (L or R)\n",
    "num_epochs = 500\n",
    "learning_rate = config['lr']\n",
    "clip=1 # gradient clipping\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "38661355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Convert sequences to PyTorch tensors\n",
    "# sequences: List of variable-length sequences\n",
    "# targets: List of target labels\n",
    "\n",
    "def pad_sequential_data(X_data, y_data):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        X_data: (list) training or test X data, sequential, not equal length\n",
    "        y_data: (list) training or test y data\n",
    "\n",
    "    Returns:\n",
    "        - same length sequence for X_data\n",
    "\n",
    "    reference: https://chat.openai.com/c/235f65e4-3a26-4418-a88c-ecf521cc5d8d\n",
    "    \"\"\"\n",
    "    sequences = [torch.tensor(seq) for seq in X_data]\n",
    "    targets = torch.tensor(y_data)\n",
    "\n",
    "    #### Sort sequences by length in descending order\n",
    "    # sequences[i] indicatess i th object (variable length)\n",
    "    # sequence[i][0] (dimension: feature numbers)\n",
    "\n",
    "    # sorted_indices = sorted(range(len(sequences)), key=lambda i: len(sequences[i][0]), reverse=True)\n",
    "    sorted_indices = sorted(range(len(sequences)), key=lambda i: len(sequences[i]), reverse=True)\n",
    "\n",
    "    #### sorted as per length\n",
    "    sequences = [sequences[i] for i in sorted_indices]\n",
    "    targets = targets[sorted_indices]\n",
    "\n",
    "    #### Pad the sequences to make them the same length (zero padding as default)\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "    return padded_sequences, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4b37d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(X_train, y_train, X_test, y_test, batch_size):\n",
    "    #### Create a TensorDataset from the padded sequences and targets\n",
    "    padded_sequences, targets = pad_sequential_data(X_train, y_train)\n",
    "    train_dataset = TensorDataset(padded_sequences, targets)\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    #### Getting train, validation data\n",
    "    test_abs = int(len(train_dataset) * 0.8)\n",
    "    train_subset, val_subset = random_split(train_dataset, [test_abs, len(train_dataset) - test_abs])\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, drop_last=True) # https://stackoverflow.com/a/53286859\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    #### Getting test data\n",
    "    padded_sequences_test, targets_test = pad_sequential_data(X_test, y_test)\n",
    "    test_dataset = TensorDataset(padded_sequences_test, targets_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True) # drop last didn't apply to test_loader to avoid null test_loader\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbaf662",
   "metadata": {},
   "source": [
    "### LSTM 2D model with packed padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a0b918f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTM2D(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTM2D, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, \n",
    "                            hidden_size, \n",
    "                            num_layers, \n",
    "                            batch_first=True,\n",
    "                            dropout = 0.3)\n",
    "        # self.batch_norm = nn.BatchNorm1d(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        packed_sequences = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        packed_out, _ = self.lstm(packed_sequences, (h0, c0))\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        # out = self.batch_norm(out[:, -1, :])\n",
    "        # out = self.fc(out)\n",
    "        # // up to here batchnorm use\n",
    "        out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "\n",
    "        out = out[:, -1, :]\n",
    "        # out = self.batch_norm(out)\n",
    "        out = self.fc(out)\n",
    "        # https://stackoverflow.com/questions/66456541/runtimeerror-cuda-error-device-side-assert-triggered-on-loss-function\n",
    "        out = self.sigmoid(out) # ouput [0, 1]\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312683a5",
   "metadata": {},
   "source": [
    "### RNN define and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4302bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "loss_history =torch.tensor([])\n",
    "\n",
    "def train_lstm(config):\n",
    "    global loss_history\n",
    "\n",
    "    model = LSTM2D(input_size, config[\"hidden_size\"], config[\"num_layers\"], num_classes).to(device)\n",
    "    # print(model)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=config[\"step_size\"], gamma=config[\"gamma\"])\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=config[\"step_size\"], gamma=0.1)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    train_loader, val_loader, test_loader = load_data(X_train, y_train, X_test, y_test, config[\"batch_size\"])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        ##################################################################\n",
    "        ##### training \n",
    "        ##################################################################\n",
    "        for batch_sequences, batch_labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 1) Calculate the sequence lengths for the current batch\n",
    "            lengths = torch.sum(batch_sequences.sum(dim=2) != 0, dim=1)\n",
    "\n",
    "            batch_sequences = batch_sequences.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            \n",
    "            # 2) Forward pass\n",
    "            output = model(batch_sequences, lengths)\n",
    "            \n",
    "            # this is possible, but I did instead output squeeze to match dimension\n",
    "            # batch_labels = torch.unsqueeze(batch_labels, 1)\n",
    "\n",
    "            # 3) Compute the loss       \n",
    "            loss = criterion(output.squeeze(), batch_labels.float())\n",
    "\n",
    "            # 4) Backward pass and optimization\n",
    "            loss.backward()\n",
    "            \n",
    "            # 5) Gradient Clipping\n",
    "            # 5-1) Gradient Norm Clipping\n",
    "            # nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0, norm_type=2)\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "            # 5-2) Gradient Value Clipping\n",
    "            # nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)\n",
    "        \n",
    "            optimizer.step()\n",
    "\n",
    "        loss_history = torch.cat([loss_history, torch.tensor([loss.item()]).float()], dim=0)\n",
    "\n",
    "        # Print the loss for every epoch\n",
    "        # print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item()}\")\n",
    "\n",
    "        ##################################################################\n",
    "        ##### Validation\n",
    "        ##################################################################\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total_val = 0\n",
    "        correct_val = 0\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            with torch.no_grad():\n",
    "                batch_sequences_val, batch_labels_val = data\n",
    "\n",
    "                # 1) Calculate the sequence lengths for the current batch\n",
    "                lengths_val = torch.sum(batch_sequences_val.sum(dim=2) != 0, dim=1)\n",
    "                batch_sequences_val = batch_sequences_val.to(device)\n",
    "                batch_labels_val = batch_labels_val.to(device)\n",
    "\n",
    "                # 2) Forward pass\n",
    "                output_val = model(batch_sequences_val, lengths_val)\n",
    "                total_val += batch_labels_val.size(0)      \n",
    "\n",
    "                ### prediction\n",
    "                pred_val = torch.round(output_val.squeeze())  # rounds to the nearest integer\n",
    "                #_, predicted = torch.max(output_val, 1)\n",
    "                \n",
    "                correct_tensor_val = pred_val.eq(batch_labels_val.float().view_as(pred_val))\n",
    "                current_correct_val = np.squeeze(correct_tensor_val.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor_val.cpu().numpy())\n",
    "                correct_val += np.sum(current_correct_val)\n",
    "\n",
    "                loss_val = criterion(output_val.squeeze(), batch_labels_val.float())\n",
    "                val_loss += loss_val.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "                # print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss}\")\n",
    "\n",
    "        # for hyperparameter tuning by Ray Tune\n",
    "        checkpoint_data = {\n",
    "            \"epoch\": epoch,\n",
    "            \"net_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        }\n",
    "\n",
    "\n",
    "        checkpoint = Checkpoint.from_dict(checkpoint_data)\n",
    "\n",
    "        session.report(\n",
    "            {\"loss\": val_loss / val_steps, \"accuracy\": correct_val / total_val},\n",
    "            checkpoint=checkpoint,\n",
    "        )\n",
    "        \n",
    "        ##################################################################\n",
    "        ##### scheduler\n",
    "        ##################################################################\n",
    "        scheduler.step()\n",
    "\n",
    "    # print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "17a03bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 21:03:13,579\tINFO tune.py:657 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th style=\"text-align: right;\">  accuracy</th><th style=\"text-align: right;\">     loss</th><th>should_checkpoint  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_lstm_32491_00000</td><td style=\"text-align: right;\">   1      </td><td style=\"text-align: right;\">0.615466 </td><td>True               </td></tr>\n",
       "<tr><td>train_lstm_32491_00001</td><td style=\"text-align: right;\">   0.96875</td><td style=\"text-align: right;\">0.1657   </td><td>True               </td></tr>\n",
       "<tr><td>train_lstm_32491_00002</td><td style=\"text-align: right;\">   0.90625</td><td style=\"text-align: right;\">0.735234 </td><td>True               </td></tr>\n",
       "<tr><td>train_lstm_32491_00003</td><td style=\"text-align: right;\">   0.90625</td><td style=\"text-align: right;\">0.714599 </td><td>True               </td></tr>\n",
       "<tr><td>train_lstm_32491_00004</td><td style=\"text-align: right;\">   0.03125</td><td style=\"text-align: right;\">0.694073 </td><td>True               </td></tr>\n",
       "<tr><td>train_lstm_32491_00005</td><td style=\"text-align: right;\">   0.90625</td><td style=\"text-align: right;\">0.667062 </td><td>True               </td></tr>\n",
       "<tr><td>train_lstm_32491_00006</td><td style=\"text-align: right;\">   0.875  </td><td style=\"text-align: right;\">0.907084 </td><td>True               </td></tr>\n",
       "<tr><td>train_lstm_32491_00007</td><td style=\"text-align: right;\">   0.96875</td><td style=\"text-align: right;\">0.170289 </td><td>True               </td></tr>\n",
       "<tr><td>train_lstm_32491_00008</td><td style=\"text-align: right;\">   0.96875</td><td style=\"text-align: right;\">0.452939 </td><td>True               </td></tr>\n",
       "<tr><td>train_lstm_32491_00009</td><td style=\"text-align: right;\">   0.90625</td><td style=\"text-align: right;\">0.666047 </td><td>True               </td></tr>\n",
       "<tr><td>train_lstm_32491_00010</td><td style=\"text-align: right;\">   0.21875</td><td style=\"text-align: right;\">0.742494 </td><td>True               </td></tr>\n",
       "<tr><td>train_lstm_32491_00011</td><td style=\"text-align: right;\">   0.125  </td><td style=\"text-align: right;\">0.695756 </td><td>True               </td></tr>\n",
       "<tr><td>train_lstm_32491_00012</td><td style=\"text-align: right;\">   0.90625</td><td style=\"text-align: right;\">0.498021 </td><td>True               </td></tr>\n",
       "<tr><td>train_lstm_32491_00013</td><td style=\"text-align: right;\">   0.9375 </td><td style=\"text-align: right;\">0.221235 </td><td>True               </td></tr>\n",
       "<tr><td>train_lstm_32491_00014</td><td style=\"text-align: right;\">   0.90625</td><td style=\"text-align: right;\">1.17719  </td><td>True               </td></tr>\n",
       "<tr><td>train_lstm_32491_00015</td><td style=\"text-align: right;\">   1      </td><td style=\"text-align: right;\">0.0975457</td><td>True               </td></tr>\n",
       "<tr><td>train_lstm_32491_00016</td><td style=\"text-align: right;\">   0.90625</td><td style=\"text-align: right;\">0.587571 </td><td>True               </td></tr>\n",
       "<tr><td>train_lstm_32491_00017</td><td style=\"text-align: right;\">   0.9375 </td><td style=\"text-align: right;\">0.447227 </td><td>True               </td></tr>\n",
       "<tr><td>train_lstm_32491_00018</td><td style=\"text-align: right;\">   0.9375 </td><td style=\"text-align: right;\">0.307423 </td><td>True               </td></tr>\n",
       "<tr><td>train_lstm_32491_00019</td><td style=\"text-align: right;\">   0.9375 </td><td style=\"text-align: right;\">0.771726 </td><td>True               </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-25 23:07:30,410\tINFO tune.py:1148 -- Total run time: 7456.83 seconds (7456.78 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'hidden_size': 128, 'num_layers': 8, 'lr': 0.025625820080429105, 'batch_size': 2, 'step_size': 40}\n",
      "Best trial final validation loss: 0.0975457183085382\n",
      "Best trial final validation accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "gpus_per_trial = 1\n",
    "num_samples = 20\n",
    "\n",
    "tune_scheduler = ASHAScheduler(\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    max_t=num_epochs,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2,\n",
    ")\n",
    "\n",
    "# ...\n",
    "result = tune.run(\n",
    "    train_lstm,\n",
    "    resources_per_trial={\"cpu\": 8, \"gpu\": gpus_per_trial},\n",
    "    config=config,\n",
    "    num_samples=num_samples,\n",
    "    scheduler=tune_scheduler)\n",
    "# https://discuss.ray.io/t/tune-run-vs-tuner-fit/7041/5\n",
    "\n",
    "best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "print(f\"Best trial config: {best_trial.config}\")\n",
    "print(f\"Best trial final validation loss: {best_trial.last_result['loss']}\")\n",
    "print(f\"Best trial final validation accuracy: {best_trial.last_result['accuracy']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "30668dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, batch_size):\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "\n",
    "    train_loader, val_loader, test_loader = load_data(X_train, y_train, X_test, y_test, batch_size)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for batch_sequences, batch_labels in test_loader:\n",
    "            # Data pre-processing\n",
    "            lengths = torch.sum(batch_sequences.sum(dim=2) != 0, dim=1)\n",
    "            batch_sequences = batch_sequences.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(batch_sequences, lengths)\n",
    "            total += batch_labels.size(0)      \n",
    "\n",
    "            ### prediction\n",
    "            pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "            #_, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            correct_tensor = pred.eq(batch_labels.float().view_as(pred))\n",
    "            current_correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "            correct += np.sum(current_correct)\n",
    "            \n",
    "            y_true.extend(batch_labels.tolist())\n",
    "            y_pred.extend(pred.tolist())\n",
    "\n",
    "        print('Test Accuracy of the model on the test data: {} %'.format(100 * correct / total))\n",
    "\n",
    "        # Calculate other evaluation metrics (precision, recall, F1-score)\n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a12a9f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the test data: 85.0 %\n",
      "Precision: 0.7224999999999999\n",
      "Recall: 0.85\n",
      "F1-score: 0.7810810810810811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mingi/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "best_trained_model = LSTM2D(input_size, best_trial.config[\"hidden_size\"], best_trial.config[\"num_layers\"], num_classes)\n",
    "best_trained_model.to(device)\n",
    "\n",
    "best_checkpoint = best_trial.checkpoint.to_air_checkpoint()\n",
    "best_checkpoint_data = best_checkpoint.to_dict()\n",
    "\n",
    "best_trained_model.load_state_dict(best_checkpoint_data[\"net_state_dict\"])\n",
    "\n",
    "### test accuracy\n",
    "test_accuracy(best_trained_model, best_trial.config[\"batch_size\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
