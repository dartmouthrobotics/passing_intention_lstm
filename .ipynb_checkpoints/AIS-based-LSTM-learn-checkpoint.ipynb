{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "756d8e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# essential packages\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dab6f09",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bb0cf124",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"aisdk_20180101\"\n",
    "howmany=100\n",
    "using_file_indices = np.arange(0,howmany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c7b4d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entire_pass = pd.DataFrame()\n",
    "\n",
    "# https://www.w3resource.com/pandas/dataframe/dataframe-to_pickle.php\n",
    "for using_file_idx in using_file_indices:\n",
    "    unpickled_df = pd.read_pickle(\"./dk_csv_20180101/aisdk_20180101_{}.pkl\".format(str(using_file_idx)))\n",
    "    unpickled_df\n",
    "    df_entire_pass = pd.concat([df_entire_pass, unpickled_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "37ad7a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>v_x</th>\n",
       "      <th>v_y</th>\n",
       "      <th>rel_dist</th>\n",
       "      <th>rel_bearing</th>\n",
       "      <th>rel_bearing_diff</th>\n",
       "      <th>Heading</th>\n",
       "      <th>valid</th>\n",
       "      <th>obj_index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:34:30</th>\n",
       "      <td>4.214136</td>\n",
       "      <td>2.391927</td>\n",
       "      <td>-0.009386</td>\n",
       "      <td>-0.006086</td>\n",
       "      <td>4.845643</td>\n",
       "      <td>0.516252</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>145.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:34:45</th>\n",
       "      <td>4.086469</td>\n",
       "      <td>2.312937</td>\n",
       "      <td>-0.008511</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>4.695626</td>\n",
       "      <td>0.515043</td>\n",
       "      <td>-0.001209</td>\n",
       "      <td>145.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:35:00</th>\n",
       "      <td>3.972708</td>\n",
       "      <td>2.235017</td>\n",
       "      <td>-0.007584</td>\n",
       "      <td>-0.005195</td>\n",
       "      <td>4.558257</td>\n",
       "      <td>0.512460</td>\n",
       "      <td>-0.002584</td>\n",
       "      <td>147.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:35:15</th>\n",
       "      <td>3.857949</td>\n",
       "      <td>2.154808</td>\n",
       "      <td>-0.007651</td>\n",
       "      <td>-0.005347</td>\n",
       "      <td>4.418933</td>\n",
       "      <td>0.509374</td>\n",
       "      <td>-0.003086</td>\n",
       "      <td>150.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:35:30</th>\n",
       "      <td>3.730337</td>\n",
       "      <td>2.078144</td>\n",
       "      <td>-0.008507</td>\n",
       "      <td>-0.005111</td>\n",
       "      <td>4.270140</td>\n",
       "      <td>0.508272</td>\n",
       "      <td>-0.001102</td>\n",
       "      <td>150.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 19:03:15</th>\n",
       "      <td>-0.262677</td>\n",
       "      <td>0.819739</td>\n",
       "      <td>-0.001342</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.860797</td>\n",
       "      <td>1.880898</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>72.0</td>\n",
       "      <td>True</td>\n",
       "      <td>99</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 19:03:30</th>\n",
       "      <td>-0.282814</td>\n",
       "      <td>0.865512</td>\n",
       "      <td>-0.001342</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.910546</td>\n",
       "      <td>1.886618</td>\n",
       "      <td>0.005720</td>\n",
       "      <td>72.0</td>\n",
       "      <td>True</td>\n",
       "      <td>99</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 19:03:45</th>\n",
       "      <td>-0.297036</td>\n",
       "      <td>0.894617</td>\n",
       "      <td>-0.000948</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.942640</td>\n",
       "      <td>1.891370</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>72.0</td>\n",
       "      <td>True</td>\n",
       "      <td>99</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 19:04:00</th>\n",
       "      <td>-0.310155</td>\n",
       "      <td>0.921015</td>\n",
       "      <td>-0.000875</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.971835</td>\n",
       "      <td>1.895622</td>\n",
       "      <td>0.004252</td>\n",
       "      <td>72.0</td>\n",
       "      <td>True</td>\n",
       "      <td>99</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 19:04:15</th>\n",
       "      <td>-0.310155</td>\n",
       "      <td>0.921015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.971835</td>\n",
       "      <td>1.895622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>True</td>\n",
       "      <td>99</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17276 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            x         y       v_x       v_y  rel_dist  \\\n",
       "Timestamp                                                               \n",
       "2018-01-01 23:34:30  4.214136  2.391927 -0.009386 -0.006086  4.845643   \n",
       "2018-01-01 23:34:45  4.086469  2.312937 -0.008511 -0.005266  4.695626   \n",
       "2018-01-01 23:35:00  3.972708  2.235017 -0.007584 -0.005195  4.558257   \n",
       "2018-01-01 23:35:15  3.857949  2.154808 -0.007651 -0.005347  4.418933   \n",
       "2018-01-01 23:35:30  3.730337  2.078144 -0.008507 -0.005111  4.270140   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2018-01-01 19:03:15 -0.262677  0.819739 -0.001342  0.003051  0.860797   \n",
       "2018-01-01 19:03:30 -0.282814  0.865512 -0.001342  0.003051  0.910546   \n",
       "2018-01-01 19:03:45 -0.297036  0.894617 -0.000948  0.001940  0.942640   \n",
       "2018-01-01 19:04:00 -0.310155  0.921015 -0.000875  0.001760  0.971835   \n",
       "2018-01-01 19:04:15 -0.310155  0.921015  0.000000  0.000000  0.971835   \n",
       "\n",
       "                     rel_bearing  rel_bearing_diff  Heading  valid  obj_index  \\\n",
       "Timestamp                                                                       \n",
       "2018-01-01 23:34:30     0.516252         -0.001975    145.0   True          0   \n",
       "2018-01-01 23:34:45     0.515043         -0.001209    145.5   True          0   \n",
       "2018-01-01 23:35:00     0.512460         -0.002584    147.0   True          0   \n",
       "2018-01-01 23:35:15     0.509374         -0.003086    150.5   True          0   \n",
       "2018-01-01 23:35:30     0.508272         -0.001102    150.0   True          0   \n",
       "...                          ...               ...      ...    ...        ...   \n",
       "2018-01-01 19:03:15     1.880898          0.006422     72.0   True         99   \n",
       "2018-01-01 19:03:30     1.886618          0.005720     72.0   True         99   \n",
       "2018-01-01 19:03:45     1.891370          0.004752     72.0   True         99   \n",
       "2018-01-01 19:04:00     1.895622          0.004252     72.0   True         99   \n",
       "2018-01-01 19:04:15     1.895622          0.000000     72.0   True         99   \n",
       "\n",
       "                    label  \n",
       "Timestamp                  \n",
       "2018-01-01 23:34:30     L  \n",
       "2018-01-01 23:34:45     L  \n",
       "2018-01-01 23:35:00     L  \n",
       "2018-01-01 23:35:15     L  \n",
       "2018-01-01 23:35:30     L  \n",
       "...                   ...  \n",
       "2018-01-01 19:03:15     L  \n",
       "2018-01-01 19:03:30     L  \n",
       "2018-01-01 19:03:45     L  \n",
       "2018-01-01 19:04:00     L  \n",
       "2018-01-01 19:04:15     L  \n",
       "\n",
       "[17276 rows x 11 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entire_pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46639c53",
   "metadata": {},
   "source": [
    "### pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "533f69e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_from_NED_to_Robotic(angle):\n",
    "    \"\"\"\n",
    "    convert radian angle based on NED frame to radian angle based on the robotics frame\n",
    "    \"\"\"\n",
    "\n",
    "    if 0 <= angle <= np.pi * 1/2:\n",
    "        converted_angle = np.pi * 1/2 - angle\n",
    "        return converted_angle\n",
    "\n",
    "    elif np.pi * 1/2 < angle < np.pi * 3/2:\n",
    "        converted_angle = - angle + np.pi * 1/2\n",
    "        return converted_angle\n",
    "\n",
    "    else: # 270 <= angle < 360\n",
    "        converted_angle = (np.pi * 5/2) - angle\n",
    "        return converted_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "91af57e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_entire_pass)):\n",
    "    df_entire_pass['heading_converted'] = convert_from_NED_to_Robotic(np.radians(df_entire_pass['Heading'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f3fd96c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>v_x</th>\n",
       "      <th>v_y</th>\n",
       "      <th>rel_dist</th>\n",
       "      <th>rel_bearing</th>\n",
       "      <th>rel_bearing_diff</th>\n",
       "      <th>Heading</th>\n",
       "      <th>valid</th>\n",
       "      <th>obj_index</th>\n",
       "      <th>label</th>\n",
       "      <th>heading_converted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:34:30</th>\n",
       "      <td>4.214136</td>\n",
       "      <td>2.391927</td>\n",
       "      <td>-0.009386</td>\n",
       "      <td>-0.006086</td>\n",
       "      <td>4.845643</td>\n",
       "      <td>0.516252</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>145.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:34:45</th>\n",
       "      <td>4.086469</td>\n",
       "      <td>2.312937</td>\n",
       "      <td>-0.008511</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>4.695626</td>\n",
       "      <td>0.515043</td>\n",
       "      <td>-0.001209</td>\n",
       "      <td>145.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:35:00</th>\n",
       "      <td>3.972708</td>\n",
       "      <td>2.235017</td>\n",
       "      <td>-0.007584</td>\n",
       "      <td>-0.005195</td>\n",
       "      <td>4.558257</td>\n",
       "      <td>0.512460</td>\n",
       "      <td>-0.002584</td>\n",
       "      <td>147.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:35:15</th>\n",
       "      <td>3.857949</td>\n",
       "      <td>2.154808</td>\n",
       "      <td>-0.007651</td>\n",
       "      <td>-0.005347</td>\n",
       "      <td>4.418933</td>\n",
       "      <td>0.509374</td>\n",
       "      <td>-0.003086</td>\n",
       "      <td>150.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 23:35:30</th>\n",
       "      <td>3.730337</td>\n",
       "      <td>2.078144</td>\n",
       "      <td>-0.008507</td>\n",
       "      <td>-0.005111</td>\n",
       "      <td>4.270140</td>\n",
       "      <td>0.508272</td>\n",
       "      <td>-0.001102</td>\n",
       "      <td>150.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 19:03:15</th>\n",
       "      <td>-0.262677</td>\n",
       "      <td>0.819739</td>\n",
       "      <td>-0.001342</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.860797</td>\n",
       "      <td>1.880898</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>72.0</td>\n",
       "      <td>True</td>\n",
       "      <td>99</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 19:03:30</th>\n",
       "      <td>-0.282814</td>\n",
       "      <td>0.865512</td>\n",
       "      <td>-0.001342</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.910546</td>\n",
       "      <td>1.886618</td>\n",
       "      <td>0.005720</td>\n",
       "      <td>72.0</td>\n",
       "      <td>True</td>\n",
       "      <td>99</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 19:03:45</th>\n",
       "      <td>-0.297036</td>\n",
       "      <td>0.894617</td>\n",
       "      <td>-0.000948</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.942640</td>\n",
       "      <td>1.891370</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>72.0</td>\n",
       "      <td>True</td>\n",
       "      <td>99</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 19:04:00</th>\n",
       "      <td>-0.310155</td>\n",
       "      <td>0.921015</td>\n",
       "      <td>-0.000875</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.971835</td>\n",
       "      <td>1.895622</td>\n",
       "      <td>0.004252</td>\n",
       "      <td>72.0</td>\n",
       "      <td>True</td>\n",
       "      <td>99</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 19:04:15</th>\n",
       "      <td>-0.310155</td>\n",
       "      <td>0.921015</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.971835</td>\n",
       "      <td>1.895622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>True</td>\n",
       "      <td>99</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17276 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            x         y       v_x       v_y  rel_dist  \\\n",
       "Timestamp                                                               \n",
       "2018-01-01 23:34:30  4.214136  2.391927 -0.009386 -0.006086  4.845643   \n",
       "2018-01-01 23:34:45  4.086469  2.312937 -0.008511 -0.005266  4.695626   \n",
       "2018-01-01 23:35:00  3.972708  2.235017 -0.007584 -0.005195  4.558257   \n",
       "2018-01-01 23:35:15  3.857949  2.154808 -0.007651 -0.005347  4.418933   \n",
       "2018-01-01 23:35:30  3.730337  2.078144 -0.008507 -0.005111  4.270140   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "2018-01-01 19:03:15 -0.262677  0.819739 -0.001342  0.003051  0.860797   \n",
       "2018-01-01 19:03:30 -0.282814  0.865512 -0.001342  0.003051  0.910546   \n",
       "2018-01-01 19:03:45 -0.297036  0.894617 -0.000948  0.001940  0.942640   \n",
       "2018-01-01 19:04:00 -0.310155  0.921015 -0.000875  0.001760  0.971835   \n",
       "2018-01-01 19:04:15 -0.310155  0.921015  0.000000  0.000000  0.971835   \n",
       "\n",
       "                     rel_bearing  rel_bearing_diff  Heading  valid  obj_index  \\\n",
       "Timestamp                                                                       \n",
       "2018-01-01 23:34:30     0.516252         -0.001975    145.0   True          0   \n",
       "2018-01-01 23:34:45     0.515043         -0.001209    145.5   True          0   \n",
       "2018-01-01 23:35:00     0.512460         -0.002584    147.0   True          0   \n",
       "2018-01-01 23:35:15     0.509374         -0.003086    150.5   True          0   \n",
       "2018-01-01 23:35:30     0.508272         -0.001102    150.0   True          0   \n",
       "...                          ...               ...      ...    ...        ...   \n",
       "2018-01-01 19:03:15     1.880898          0.006422     72.0   True         99   \n",
       "2018-01-01 19:03:30     1.886618          0.005720     72.0   True         99   \n",
       "2018-01-01 19:03:45     1.891370          0.004752     72.0   True         99   \n",
       "2018-01-01 19:04:00     1.895622          0.004252     72.0   True         99   \n",
       "2018-01-01 19:04:15     1.895622          0.000000     72.0   True         99   \n",
       "\n",
       "                    label  heading_converted  \n",
       "Timestamp                                     \n",
       "2018-01-01 23:34:30     L           0.314159  \n",
       "2018-01-01 23:34:45     L           0.314159  \n",
       "2018-01-01 23:35:00     L           0.314159  \n",
       "2018-01-01 23:35:15     L           0.314159  \n",
       "2018-01-01 23:35:30     L           0.314159  \n",
       "...                   ...                ...  \n",
       "2018-01-01 19:03:15     L           0.314159  \n",
       "2018-01-01 19:03:30     L           0.314159  \n",
       "2018-01-01 19:03:45     L           0.314159  \n",
       "2018-01-01 19:04:00     L           0.314159  \n",
       "2018-01-01 19:04:15     L           0.314159  \n",
       "\n",
       "[17276 rows x 12 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entire_pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d392c52",
   "metadata": {},
   "source": [
    "## Train, test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "526595ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 80 \n",
      " test size: 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([26, 86,  2, 55, 75, 93, 16, 73, 54, 95, 53, 92, 78, 13,  7, 30, 22,\n",
       "       24, 33,  8, 43, 62,  3, 71, 45, 48,  6, 99, 82, 76, 60, 80, 90, 68,\n",
       "       51, 27, 18, 56, 63, 74,  1, 61, 42, 41,  4, 15, 17, 40, 38,  5, 91,\n",
       "       59,  0, 34, 28, 50, 11, 35, 23, 52, 10, 31, 66, 57, 79, 85, 32, 84,\n",
       "       14, 89, 19, 29, 49, 97, 98, 69, 20, 94, 72, 77])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.geeksforgeeks.org/how-to-randomly-select-elements-of-an-array-with-numpy-in-python/\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "# for train, test data\n",
    "use_df = df_entire_pass.loc[(df_entire_pass.valid == True)] # to be used, valid df\n",
    "unique_id = use_df.obj_index.unique()\n",
    "\n",
    "# data split\n",
    "train_data_size = int(len(unique_id) * 0.8)\n",
    "test_data_size = len(unique_id) - train_data_size\n",
    "print(\"train size: {} \\n test size: {}\".format(train_data_size, test_data_size))\n",
    "\n",
    "# split obj indexes\n",
    "train_obj_id = np.random.choice(unique_id, size = train_data_size, replace=False)\n",
    "test_obj_id = np.setdiff1d(unique_id, train_obj_id)\n",
    "train_obj_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "57ab2231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectory_before_pass(df_input, obj_id_array):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        - df_input: data_frame for training or test\n",
    "\n",
    "    Returns:\n",
    "        - cropped dataframe with position only ahead for predicting the direction\n",
    "    \"\"\"\n",
    "    df_cropped = pd.DataFrame()\n",
    "    for idx, obj_id in enumerate(obj_id_array):\n",
    "        # TODO backside too\n",
    "        df_cropped = pd.concat([df_cropped, df_input.loc[(df_input['obj_index'] == obj_id) & \\\n",
    "                                                         (df_input['x'] > 0.0)]], ignore_index=True)\n",
    "    return df_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "adddad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dimension(x_data, y_data):\n",
    "    if len(x_data) == len(y_data):\n",
    "        print(\"Input, output dimension is same. good to go\")\n",
    "    else:\n",
    "        raise ValueError(\"Input, output dimension is different. Double check!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "27158cab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>v_x</th>\n",
       "      <th>v_y</th>\n",
       "      <th>rel_dist</th>\n",
       "      <th>rel_bearing</th>\n",
       "      <th>rel_bearing_diff</th>\n",
       "      <th>Heading</th>\n",
       "      <th>valid</th>\n",
       "      <th>obj_index</th>\n",
       "      <th>label</th>\n",
       "      <th>heading_converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.698369</td>\n",
       "      <td>-1.403258</td>\n",
       "      <td>-0.009192</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>4.903448</td>\n",
       "      <td>-0.290235</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>210.0</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.565623</td>\n",
       "      <td>-1.343425</td>\n",
       "      <td>-0.008850</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>4.759171</td>\n",
       "      <td>-0.286171</td>\n",
       "      <td>0.004064</td>\n",
       "      <td>210.0</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.422403</td>\n",
       "      <td>-1.278315</td>\n",
       "      <td>-0.009548</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>4.603449</td>\n",
       "      <td>-0.281385</td>\n",
       "      <td>0.004786</td>\n",
       "      <td>210.0</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.279420</td>\n",
       "      <td>-1.213489</td>\n",
       "      <td>-0.009532</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>4.448145</td>\n",
       "      <td>-0.276310</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>210.0</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.138647</td>\n",
       "      <td>-1.151726</td>\n",
       "      <td>-0.009385</td>\n",
       "      <td>0.004118</td>\n",
       "      <td>4.295914</td>\n",
       "      <td>-0.271418</td>\n",
       "      <td>0.004892</td>\n",
       "      <td>210.0</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10445</th>\n",
       "      <td>0.336464</td>\n",
       "      <td>0.919474</td>\n",
       "      <td>-0.004602</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.979102</td>\n",
       "      <td>1.220000</td>\n",
       "      <td>0.068773</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10446</th>\n",
       "      <td>0.262734</td>\n",
       "      <td>0.929513</td>\n",
       "      <td>-0.004915</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.965931</td>\n",
       "      <td>1.295325</td>\n",
       "      <td>0.075325</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10447</th>\n",
       "      <td>0.198039</td>\n",
       "      <td>0.939042</td>\n",
       "      <td>-0.004313</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.959697</td>\n",
       "      <td>1.362947</td>\n",
       "      <td>0.067623</td>\n",
       "      <td>193.5</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10448</th>\n",
       "      <td>0.129021</td>\n",
       "      <td>0.949109</td>\n",
       "      <td>-0.004601</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.957838</td>\n",
       "      <td>1.435685</td>\n",
       "      <td>0.072738</td>\n",
       "      <td>194.0</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10449</th>\n",
       "      <td>0.050902</td>\n",
       "      <td>0.962536</td>\n",
       "      <td>-0.005208</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.963881</td>\n",
       "      <td>1.517962</td>\n",
       "      <td>0.082278</td>\n",
       "      <td>193.5</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10450 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x         y       v_x       v_y  rel_dist  rel_bearing  \\\n",
       "0      4.698369 -1.403258 -0.009192  0.004104  4.903448    -0.290235   \n",
       "1      4.565623 -1.343425 -0.008850  0.003989  4.759171    -0.286171   \n",
       "2      4.422403 -1.278315 -0.009548  0.004341  4.603449    -0.281385   \n",
       "3      4.279420 -1.213489 -0.009532  0.004322  4.448145    -0.276310   \n",
       "4      4.138647 -1.151726 -0.009385  0.004118  4.295914    -0.271418   \n",
       "...         ...       ...       ...       ...       ...          ...   \n",
       "10445  0.336464  0.919474 -0.004602  0.000695  0.979102     1.220000   \n",
       "10446  0.262734  0.929513 -0.004915  0.000669  0.965931     1.295325   \n",
       "10447  0.198039  0.939042 -0.004313  0.000635  0.959697     1.362947   \n",
       "10448  0.129021  0.949109 -0.004601  0.000671  0.957838     1.435685   \n",
       "10449  0.050902  0.962536 -0.005208  0.000895  0.963881     1.517962   \n",
       "\n",
       "       rel_bearing_diff  Heading  valid  obj_index label  heading_converted  \n",
       "0              0.003865    210.0   True         26     L           0.314159  \n",
       "1              0.004064    210.0   True         26     L           0.314159  \n",
       "2              0.004786    210.0   True         26     L           0.314159  \n",
       "3              0.005074    210.0   True         26     L           0.314159  \n",
       "4              0.004892    210.0   True         26     L           0.314159  \n",
       "...                 ...      ...    ...        ...   ...                ...  \n",
       "10445          0.068773    193.0   True         77     L           0.314159  \n",
       "10446          0.075325    193.0   True         77     L           0.314159  \n",
       "10447          0.067623    193.5   True         77     L           0.314159  \n",
       "10448          0.072738    194.0   True         77     L           0.314159  \n",
       "10449          0.082278    193.5   True         77     L           0.314159  \n",
       "\n",
       "[10450 rows x 12 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "df_cropped_train = get_trajectory_before_pass(df_entire_pass, train_obj_id)\n",
    "df_cropped_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "28e857f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(df_cropped_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f11c1f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(df_cropped_train['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "336d5754",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>v_x</th>\n",
       "      <th>v_y</th>\n",
       "      <th>rel_dist</th>\n",
       "      <th>rel_bearing</th>\n",
       "      <th>rel_bearing_diff</th>\n",
       "      <th>Heading</th>\n",
       "      <th>valid</th>\n",
       "      <th>obj_index</th>\n",
       "      <th>label</th>\n",
       "      <th>heading_converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.531333</td>\n",
       "      <td>4.889139</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>-0.007141</td>\n",
       "      <td>4.917926</td>\n",
       "      <td>1.462545</td>\n",
       "      <td>-0.002815</td>\n",
       "      <td>90.625000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>R</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.531943</td>\n",
       "      <td>4.777563</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>-0.007438</td>\n",
       "      <td>4.807085</td>\n",
       "      <td>1.459911</td>\n",
       "      <td>-0.002634</td>\n",
       "      <td>90.937500</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>R</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.531469</td>\n",
       "      <td>4.642245</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.009021</td>\n",
       "      <td>4.672568</td>\n",
       "      <td>1.456807</td>\n",
       "      <td>-0.003104</td>\n",
       "      <td>91.250000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>R</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.534526</td>\n",
       "      <td>4.534370</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>-0.007192</td>\n",
       "      <td>4.565767</td>\n",
       "      <td>1.453455</td>\n",
       "      <td>-0.003353</td>\n",
       "      <td>91.562500</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>R</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.537584</td>\n",
       "      <td>4.426495</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>-0.007192</td>\n",
       "      <td>4.459020</td>\n",
       "      <td>1.449941</td>\n",
       "      <td>-0.003513</td>\n",
       "      <td>91.875000</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>R</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5089</th>\n",
       "      <td>0.094810</td>\n",
       "      <td>-0.029229</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.099214</td>\n",
       "      <td>-0.299046</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>97.163636</td>\n",
       "      <td>True</td>\n",
       "      <td>96</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5090</th>\n",
       "      <td>0.096544</td>\n",
       "      <td>-0.029880</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.101062</td>\n",
       "      <td>-0.300143</td>\n",
       "      <td>-0.001096</td>\n",
       "      <td>95.109091</td>\n",
       "      <td>True</td>\n",
       "      <td>96</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5091</th>\n",
       "      <td>0.098277</td>\n",
       "      <td>-0.030530</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.102910</td>\n",
       "      <td>-0.301199</td>\n",
       "      <td>-0.001057</td>\n",
       "      <td>93.054545</td>\n",
       "      <td>True</td>\n",
       "      <td>96</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5092</th>\n",
       "      <td>0.100011</td>\n",
       "      <td>-0.031180</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.104758</td>\n",
       "      <td>-0.302219</td>\n",
       "      <td>-0.001019</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>96</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5093</th>\n",
       "      <td>0.042027</td>\n",
       "      <td>-0.023922</td>\n",
       "      <td>-0.003866</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.048358</td>\n",
       "      <td>-0.517463</td>\n",
       "      <td>-0.215244</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>96</td>\n",
       "      <td>L</td>\n",
       "      <td>0.314159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5094 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x         y       v_x       v_y  rel_dist  rel_bearing  \\\n",
       "0     0.531333  4.889139  0.000172 -0.007141  4.917926     1.462545   \n",
       "1     0.531943  4.777563  0.000041 -0.007438  4.807085     1.459911   \n",
       "2     0.531469  4.642245 -0.000032 -0.009021  4.672568     1.456807   \n",
       "3     0.534526  4.534370  0.000204 -0.007192  4.565767     1.453455   \n",
       "4     0.537584  4.426495  0.000204 -0.007192  4.459020     1.449941   \n",
       "...        ...       ...       ...       ...       ...          ...   \n",
       "5089  0.094810 -0.029229  0.000007  0.000066  0.099214    -0.299046   \n",
       "5090  0.096544 -0.029880  0.000116 -0.000043  0.101062    -0.300143   \n",
       "5091  0.098277 -0.030530  0.000116 -0.000043  0.102910    -0.301199   \n",
       "5092  0.100011 -0.031180  0.000116 -0.000043  0.104758    -0.302219   \n",
       "5093  0.042027 -0.023922 -0.003866  0.000484  0.048358    -0.517463   \n",
       "\n",
       "      rel_bearing_diff     Heading  valid  obj_index label  heading_converted  \n",
       "0            -0.002815   90.625000   True          9     R           0.314159  \n",
       "1            -0.002634   90.937500   True          9     R           0.314159  \n",
       "2            -0.003104   91.250000   True          9     R           0.314159  \n",
       "3            -0.003353   91.562500   True          9     R           0.314159  \n",
       "4            -0.003513   91.875000   True          9     R           0.314159  \n",
       "...                ...         ...    ...        ...   ...                ...  \n",
       "5089          0.009800   97.163636   True         96     L           0.314159  \n",
       "5090         -0.001096   95.109091   True         96     L           0.314159  \n",
       "5091         -0.001057   93.054545   True         96     L           0.314159  \n",
       "5092         -0.001019   91.000000   True         96     L           0.314159  \n",
       "5093         -0.215244  118.000000   True         96     L           0.314159  \n",
       "\n",
       "[5094 rows x 12 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data\n",
    "df_cropped_test = get_trajectory_before_pass(df_entire_pass, test_obj_id)\n",
    "df_cropped_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9785d11",
   "metadata": {},
   "source": [
    "## Train, test data onehot encoding and extract specific cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ff3e75e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input, output dimension is same. good to go\n",
      "Input, output dimension is same. good to go\n"
     ]
    }
   ],
   "source": [
    "# columns to extract\n",
    "columns_for_x = ['x', 'y', 'rel_dist', 'rel_bearing', 'heading_converted']\n",
    "# columns_for_x = ['r_value', 'atan']\n",
    "columns_for_y = ['label']\n",
    "\n",
    "# one hot encoding for y target\n",
    "one_hot_lookup = torch.eye(2).tolist()\n",
    "\n",
    "# df to array\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "#### train dataset\n",
    "for obj_id, df_by_ID in df_cropped_train.groupby('obj_index'):\n",
    "    X_train.append(df_by_ID[columns_for_x].values.tolist())\n",
    "    # y_train.append(one_hot_lookup[0] if df_by_ID[columns_for_y].values[-1][0] == \"L\" else one_hot_lookup[1]) # last row, only char\n",
    "    y_train.append(0 if df_by_ID[columns_for_y].values[-1][0] == \"L\" else 1) # last row, only char\n",
    "\n",
    "    #### double check train dataset\n",
    "check_dimension(X_train, y_train)\n",
    "\n",
    "#### test dataset\n",
    "for obj_id, df_by_ID in df_cropped_test.groupby('obj_index'):\n",
    "    X_test.append(df_by_ID[columns_for_x].values.tolist())\n",
    "    # y_test.append(one_hot_lookup[0] if df_by_ID[columns_for_y].values[-1][0] == \"L\" else one_hot_lookup[1]) # last row, only char\n",
    "    y_test.append(0 if df_by_ID[columns_for_y].values[-1][0] == \"L\" else 1) # last row, only char\n",
    "\n",
    "#### double check test dataset\n",
    "check_dimension(X_test, y_test)\n",
    "\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb68535",
   "metadata": {},
   "source": [
    "## RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e032b8cd",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b59c5a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequence_length = 10 # number of timestamps # padding\n",
    "input_size = 5 # number of columns, features\n",
    "batch_size = 32 # number of samples sent to the model at one time\n",
    "\n",
    "hidden_size = 500 # dimension of hidden state\n",
    "num_layers = 10 # total layer\n",
    "num_classes = 1 # output class (L or R)\n",
    "num_epochs = 300\n",
    "learning_rate = 0.008\n",
    "clip=1 # gradient clipping\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "38661355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# Convert sequences to PyTorch tensors\n",
    "# sequences: List of variable-length sequences\n",
    "# targets: List of target labels\n",
    "\n",
    "def pad_sequential_data(X_data, y_data):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        X_data: (list) training or test X data, sequential, not equal length\n",
    "        y_data: (list) training or test y data\n",
    "\n",
    "    Returns:\n",
    "        - same length sequence for X_data\n",
    "\n",
    "    reference: https://chat.openai.com/c/235f65e4-3a26-4418-a88c-ecf521cc5d8d\n",
    "    \"\"\"\n",
    "    sequences = [torch.tensor(seq) for seq in X_data]\n",
    "    targets = torch.tensor(y_data)\n",
    "\n",
    "    #### Sort sequences by length in descending order\n",
    "    # sequences[i] indicatess i th object (variable length)\n",
    "    # sequence[i][0] (dimension: feature numbers)\n",
    "\n",
    "    # sorted_indices = sorted(range(len(sequences)), key=lambda i: len(sequences[i][0]), reverse=True)\n",
    "    sorted_indices = sorted(range(len(sequences)), key=lambda i: len(sequences[i]), reverse=True)\n",
    "\n",
    "    #### sorted as per length\n",
    "    sequences = [sequences[i] for i in sorted_indices]\n",
    "    targets = targets[sorted_indices]\n",
    "\n",
    "    #### Pad the sequences to make them the same length (zero padding as default)\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "    return padded_sequences, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4b37d305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 2956, 5])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Create a TensorDataset from the padded sequences and targets\n",
    "padded_sequences, targets = pad_sequential_data(X_train, y_train)\n",
    "train_dataset = TensorDataset(padded_sequences, targets)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "padded_sequences_test, targets_test = pad_sequential_data(X_test, y_test)\n",
    "test_dataset = TensorDataset(padded_sequences_test, targets_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "padded_sequences.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f861287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padded_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312683a5",
   "metadata": {},
   "source": [
    "### RNN define and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "950e1bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an RNN model\n",
    "# class LSTM(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "#         super(LSTM, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "\n",
    "#         # https://discuss.pytorch.org/t/could-someone-explain-batch-first-true-in-lstm/15402/2\n",
    "#         # self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "#         self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "#         self.batch_norm = nn.BatchNorm1d(hidden_size)\n",
    "#         self.fc = nn.Linear(hidden_size, output_size)\n",
    "#         self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         ##### RNN\n",
    "#         # _, hidden = self.rnn(x)\n",
    "#         # output = self.fc(hidden.squeeze(0))\n",
    "#         # return output\n",
    "\n",
    "\n",
    "#         ##### LSTM\n",
    "#         # h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "#         # c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "#         h0 = torch.zeros(self.num_layers, x.data.size(0), self.hidden_size).to(device)\n",
    "#         c0 = torch.zeros(self.num_layers, x.data.size(0), self.hidden_size).to(device)\n",
    "\n",
    "#         # Forward propagate LSTM\n",
    "#         out, hidden = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "#         # Decode the hidden state of the last time step\n",
    "#         # out = self.batch_norm(out[:, -1, :])\n",
    "#         # out = self.fc(out)\n",
    "#         # // up to here batchnorm use\n",
    "\n",
    "#         out = self.fc(out[:, -1, :])\n",
    "#         out = self.sigmoid(out)\n",
    "#         return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "48fb73d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "# print(model)\n",
    "\n",
    "# # Loss and optimizer\n",
    "# # criterion = nn.CrossEntropyLoss()\n",
    "# # criterion = nn.BCEWithLogitsLoss() ## using\n",
    "# criterion = nn.BCELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# import torch.optim as optim\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c6ecc9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train mode\n",
    "# model.train()\n",
    "\n",
    "# loss_history =torch.tensor([])\n",
    "# for epoch in range(num_epochs):\n",
    "#     for batch_sequences, batch_targets in train_loader:\n",
    "#         # print(batch_sequences.size())\n",
    "#         # print(batch_targets.size())\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # 1) Pack the sequences before passing them to the RNN\n",
    "#         # TODO do we really need this?\n",
    "#         sequence_lengths = [len(seq) for seq in batch_sequences]\n",
    "#         packed_sequences = pack_padded_sequence(batch_sequences, sequence_lengths, batch_first=True, enforce_sorted=False).to(device)\n",
    "\n",
    "#         batch_sequences = batch_sequences.to(device)\n",
    "#         batch_targets = batch_targets.to(device)\n",
    "\n",
    "#         # 2) Forward pass\n",
    "#         output = model(batch_sequences)\n",
    "#         # output = model(packed_sequences)\n",
    "#         # Compute the loss\n",
    "#         loss = criterion(output.squeeze(), batch_targets.float())\n",
    "\n",
    "#         # 3) Backward pass and optimization\n",
    "#         loss.backward()\n",
    "\n",
    "          # 4) Gradient clipping\n",
    "#         # nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "#         optimizer.step()\n",
    "\n",
    "#     loss_history = torch.cat([loss_history, torch.tensor([loss.item()]).float()], dim=0)\n",
    "\n",
    "#     # Print the loss for every epoch\n",
    "#     if epoch % 1 == 0:\n",
    "#         print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "# #     scheduler.step()\n",
    "# #     print('Epoch-{0} lr: {1}'.format(epoch, optimizer.param_groups[0]['lr']))\n",
    "# #     if epoch % 5 == 0:print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b7149c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.plot(range(1,num_epochs+1), loss_history, label = \"train loss\", linewidth=3)\n",
    "# plt.xlabel(\"Epoch\", fontsize=20)\n",
    "# plt.ylabel(\"loss\", fontsize=20)\n",
    "# plt.legend(fontsize=20)\n",
    "# plt.xticks(fontsize=15)\n",
    "# plt.yticks(fontsize=15)\n",
    "# plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d654f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the model\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for batch_sequences, batch_targets in test_loader:\n",
    "#         batch_sequences = batch_sequences.to(device)\n",
    "#         batch_targets = batch_targets.to(device)\n",
    "\n",
    "#         output = model(batch_sequences)\n",
    "#         total += batch_targets.size(0)\n",
    "#         ### prediction (old)\n",
    "#         # _, predicted = torch.max(output.data, 1) # binary classification\n",
    "#         # total += batch_targets.size(0)\n",
    "#         # correct += (predicted == batch_targets).sum().item()\n",
    "\n",
    "#         ### prediction\n",
    "#         pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "#         correct_tensor = pred.eq(batch_targets.float().view_as(pred))\n",
    "#         current_correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "#         correct += np.sum(current_correct)\n",
    "\n",
    "#     print('Test Accuracy of the model on the test data: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e6eb161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sequence_length = 10 # number of timestamps # padding\n",
    "# input_size = 5 # number of columns, features\n",
    "# batch_size = 32 # number of samples sent to the model at one time\n",
    "\n",
    "# hidden_size = 500 # dimension of hidden state\n",
    "# num_layers = 10 # total layer\n",
    "# num_classes = 1 # output class (L or R)\n",
    "# num_epochs = 300\n",
    "# learning_rate = 0.008\n",
    "# clip=1 # gradient clipping\n",
    "\n",
    "# # Device configuration\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65a5f6b",
   "metadata": {},
   "source": [
    "### LSTM 2D model with packed padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a0b918f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTM2D(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTM2D, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "#         self.batch_norm = nn.BatchNorm1d(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "#         x = x.unsqueeze(2)\n",
    "\n",
    "        packed_sequences = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        packed_out, _ = self.lstm(packed_sequences, (h0, c0))\n",
    "        \n",
    "#         # Decode the hidden state of the last time step\n",
    "#         # out = self.batch_norm(out[:, -1, :])\n",
    "#         # out = self.fc(out)\n",
    "#         # // up to here batchnorm use\n",
    "        out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "\n",
    "        out = out[:, -1, :]\n",
    "#         out = self.batch_norm(out)\n",
    "        out = self.fc(out)\n",
    "        # https://stackoverflow.com/questions/66456541/runtimeerror-cuda-error-device-side-assert-triggered-on-loss-function\n",
    "        out = self.sigmoid(out) # ouput [0, 1]\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5f8f5083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM2D(\n",
      "  (lstm): LSTM(5, 500, num_layers=10, batch_first=True)\n",
      "  (fc): Linear(in_features=500, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LSTM2D(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4302bf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.8079022169113159\n",
      "Epoch 2/100, Loss: 0.6762251853942871\n",
      "Epoch 3/100, Loss: 0.6688231229782104\n",
      "Epoch 4/100, Loss: 0.6452735066413879\n",
      "Epoch 5/100, Loss: 0.6684287190437317\n",
      "Epoch 6/100, Loss: 0.641129732131958\n",
      "Epoch 7/100, Loss: 0.6338518857955933\n",
      "Epoch 8/100, Loss: 0.7409546375274658\n",
      "Epoch 9/100, Loss: 0.622137188911438\n",
      "Epoch 10/100, Loss: 0.6073150038719177\n",
      "Epoch 11/100, Loss: 0.6087335348129272\n",
      "Epoch 12/100, Loss: 0.6112890839576721\n",
      "Epoch 13/100, Loss: 0.6149890422821045\n",
      "Epoch 14/100, Loss: 0.6002646684646606\n",
      "Epoch 15/100, Loss: 0.606802225112915\n",
      "Epoch 16/100, Loss: 0.6205863952636719\n",
      "Epoch 17/100, Loss: 0.5869274735450745\n",
      "Epoch 18/100, Loss: 0.5805400609970093\n",
      "Epoch 19/100, Loss: 0.5898867845535278\n",
      "Epoch 20/100, Loss: 0.5444691181182861\n",
      "Epoch 21/100, Loss: 0.6574556827545166\n",
      "Epoch 22/100, Loss: 0.599285364151001\n",
      "Epoch 23/100, Loss: 0.5228704810142517\n",
      "Epoch 24/100, Loss: 0.6093326807022095\n",
      "Epoch 25/100, Loss: 0.5533369779586792\n",
      "Epoch 26/100, Loss: 0.5506768822669983\n",
      "Epoch 27/100, Loss: 0.549554169178009\n",
      "Epoch 28/100, Loss: 0.5222668647766113\n",
      "Epoch 29/100, Loss: 0.5279707908630371\n",
      "Epoch 30/100, Loss: 0.5220441818237305\n",
      "Epoch 31/100, Loss: 0.6130525469779968\n",
      "Epoch 32/100, Loss: 0.52900230884552\n",
      "Epoch 33/100, Loss: 0.5623021125793457\n",
      "Epoch 34/100, Loss: 0.5118305683135986\n",
      "Epoch 35/100, Loss: 0.5115489363670349\n",
      "Epoch 36/100, Loss: 0.5273253321647644\n",
      "Epoch 37/100, Loss: 0.5179880857467651\n",
      "Epoch 38/100, Loss: 0.4865427315235138\n",
      "Epoch 39/100, Loss: 0.5003236532211304\n",
      "Epoch 40/100, Loss: 0.5137337446212769\n",
      "Epoch 41/100, Loss: 0.4878929853439331\n",
      "Epoch 42/100, Loss: 0.4810081422328949\n",
      "Epoch 43/100, Loss: 0.47613808512687683\n",
      "Epoch 44/100, Loss: 0.4520013928413391\n",
      "Epoch 45/100, Loss: 0.46904826164245605\n",
      "Epoch 46/100, Loss: 0.46628302335739136\n",
      "Epoch 47/100, Loss: 0.5686126947402954\n",
      "Epoch 48/100, Loss: 0.4394949972629547\n",
      "Epoch 49/100, Loss: 0.4598452150821686\n",
      "Epoch 50/100, Loss: 0.45857083797454834\n",
      "Epoch 51/100, Loss: 0.5260744094848633\n",
      "Epoch 52/100, Loss: 0.45741069316864014\n",
      "Epoch 53/100, Loss: 0.4342322051525116\n",
      "Epoch 54/100, Loss: 0.47974497079849243\n",
      "Epoch 55/100, Loss: 0.43336164951324463\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "loss_history =torch.tensor([])\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_sequences, batch_labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 1) Calculate the sequence lengths for the current batch\n",
    "        lengths = torch.sum(batch_sequences.sum(dim=2) != 0, dim=1)\n",
    "\n",
    "        batch_sequences = batch_sequences.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        \n",
    "        # 2) Forward pass\n",
    "        output = model(batch_sequences, lengths)\n",
    "        \n",
    "        # this is possible, but I did instead output squeeze to match dimension\n",
    "        # batch_labels = torch.unsqueeze(batch_labels, 1)\n",
    "\n",
    "        # 3) Compute the loss       \n",
    "        loss = criterion(output.squeeze(), batch_labels.float())\n",
    "\n",
    "        # 4) Backward pass and optimization\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5) Gradient Clipping\n",
    "        # 5-1) Gradient Norm Clipping\n",
    "        # nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0, norm_type=2)\n",
    "        # 5-2) Gradient Value Clipping\n",
    "#         nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)\n",
    "\n",
    "        \n",
    "        optimizer.step()\n",
    "    loss_history = torch.cat([loss_history, torch.tensor([loss.item()]).float()], dim=0)\n",
    "    scheduler.step()\n",
    "    # Print the loss for every epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287126e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(1,num_epochs+1), loss_history, label = \"train loss\", linewidth=3)\n",
    "plt.xlabel(\"Epoch\", fontsize=20)\n",
    "plt.ylabel(\"loss\", fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8fb4ca",
   "metadata": {},
   "source": [
    "* __packed padding__: \n",
    "    - resolving unreasonable overshooting\n",
    "    - resolving the issue of zero padding and not knowing the original length\n",
    "* __batch normalization__\n",
    "    - so far overshooting\n",
    "* __learning rate__\n",
    "    - a bit large (0.001 -> 0.005) works better\n",
    "* __layer and hidden size__\n",
    "    - not too much large, but larger one works well\n",
    "* last batch dropout\n",
    "    - works okay\n",
    "* __gradient clipping__\n",
    "* __gradient scheduler for decay__\n",
    "\n",
    "Not yet applied\n",
    "* dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7988095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_sequences, batch_targets in test_loader:\n",
    "        lengths = torch.sum(batch_sequences.sum(dim=2) != 0, dim=1)\n",
    "\n",
    "        batch_sequences = batch_sequences.to(device)\n",
    "        batch_targets = batch_targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(batch_sequences, lengths)\n",
    "        total += batch_targets.size(0)\n",
    "\n",
    "        ### prediction\n",
    "        pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "        correct_tensor = pred.eq(batch_targets.float().view_as(pred))\n",
    "        current_correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "        correct += np.sum(current_correct)\n",
    "\n",
    "    print('Test Accuracy of the model on the test data: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13a8863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/how-to-use-lstm-for-a-time-series-classification-task/130559/4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
